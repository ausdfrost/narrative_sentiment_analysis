{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "shIb96uBh6JV"
      },
      "source": [
        "# Narrative Sentiment Analysis using NLP\n",
        "\n",
        "A project for CSNL by Aussie Frost\n",
        "- Started: 05/23/2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHwHIPy8D57P",
        "outputId": "cb5638dd-4c4c-4c96-f8b1-e9ac65314f4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/austinfroste/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/austinfroste/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CijgLPUfD93b"
      },
      "outputs": [],
      "source": [
        "# 1) Spell Check\n",
        "# 2) Stem/tokenize word\n",
        "# 3) Bag of Words\n",
        "# 4) Algo: methods such as regression, K-Nearest Neighbors, Neural Nets, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_Uwc3smOKFVc"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/eliotjmartin/uodsc-club/main/twitter_train.csv\")\n",
        "train = train.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X5jTRLCfLwfM",
        "outputId": "5523a4fe-bafa-44e8-e44a-b3b901953cba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xKqrdmxuV0mr"
      },
      "source": [
        "## Preprocessing Techniques"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oZo4tv8QV58r"
      },
      "source": [
        "##### How can we make our textual data easier to work with?\n",
        "- Remove \"stop words\" that do not add meaning to the sentence\n",
        "- Map synonyms to a single word to reduce the number of unique features and increase the frequency of important words\n",
        "- Reduce the feature space by stemming each word to its root form\n",
        "- Create a representation of the sentence using techniques such as bag of words or embeddings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VqiOD3fGV92D"
      },
      "source": [
        "#### First, let's create a function to tokenize a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y7VdT9sqV1MP"
      },
      "outputs": [],
      "source": [
        "def tokenizer(sentence):\n",
        "    # remove punctuation from sentence\n",
        "    sentence = ''.join(\n",
        "        char for char in sentence if char not in string.punctuation\n",
        "    )\n",
        "    # tokenizing the sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    return [token.lower() for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DaieKCYrWATw",
        "outputId": "269059ca-6e55-423c-be67-9af5b17c47ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' I`d have responded, if I were going'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = train.loc[0, 'text']\n",
        "example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSASvEjIWCic",
        "outputId": "ffc0d0bb-41d7-4c37-8077-3d258a7d8430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id', 'have', 'responded', 'if', 'i', 'were', 'going']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(example)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9PpxYRpdWJU5"
      },
      "source": [
        "#### Let's define our stop words (meaningless words that do not add too much value to the meaning of our sentence)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k_iJNK1yWNTn"
      },
      "source": [
        "*Example: what sort of words are in the stop words list?*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRl-tbHIWEfu",
        "outputId": "3bbc63ba-d074-4d0f-a022-d31157a45347"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "'do' in stop_words, 'when' in stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3hmVk5ZWQzK",
        "outputId": "ceb842d7-b50f-4403-a53c-3a212fcaac00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(stop_words)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sVF2O2GlW6g_"
      },
      "source": [
        "### Your turn:\n",
        "\n",
        "Write a function that accepts a list of tokens and returns the same list of tokens without stop words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RR9Exsi1WYFJ"
      },
      "outputs": [],
      "source": [
        "def stopword_destroyer(tokens): \n",
        "  tokens_no_sw = []\n",
        "\n",
        "  for word in tokens:\n",
        "    if word not in stop_words:\n",
        "      tokens_no_sw.append(word)\n",
        "\n",
        "  return tokens_no_sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BhPnIxUkW9Pm"
      },
      "outputs": [],
      "source": [
        "assert stopword_destroyer(tokenizer(example)) == ['id', 'responded', 'going']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FpxgPBdVXPiE"
      },
      "source": [
        "#### Stemming\n",
        "\n",
        "Stemming reduces words to their root form by removing parts of the word like prefixes and suffixes. This also helps to reduce the feature space as well as increase the frequency of similar words (like \"run\", \"running\", and \"runs\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zix8-HJGXAMh"
      },
      "outputs": [],
      "source": [
        "# initialize the porter stemmer from NLTK\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ca8Z4cpiXSNd",
        "outputId": "cf0b17c2-ddb5-4b5b-f8e7-46ba9baa1742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'run'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemmer.stem(\"running\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_BpJn4iWXdVI"
      },
      "source": [
        "## Your turn\n",
        "\n",
        "Similar to above, this function should accept a list of tokens(list of words) as an argument and return the stemmed tokens (as a list)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UQisw8EzXTx6"
      },
      "outputs": [],
      "source": [
        "def stemmerizer(tokens):\n",
        "  stemmed_tokens = []\n",
        "  for i in tokens:\n",
        "    stemmed_tokens.append(stemmer.stem(i))\n",
        "  return stemmed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zhTDR0j1XgXG"
      },
      "outputs": [],
      "source": [
        "assert stemmerizer(tokenizer(example)) == ['id', 'have', 'respond', 'if', 'i', 'were', 'go']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vb1-b6XxYJ"
      },
      "source": [
        "#### A Preprocessing Function\n",
        "\n",
        "Now we can combine the preprocessing techniques described above into a single function that we can use to remove noise and irrelevant information from our data.\n",
        "\n",
        "The preprocess function in the cell below takes a sentence as input, removes punctuation and stop words, stems each word in the sentence, maps synonymous words to a single word, and returns the preprocessed sentence as a list of words."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jHJXkBInYoIP"
      },
      "source": [
        "### Your Turn\n",
        "\n",
        "Fill in the missing parts in the `Preprocess` using the functions we made above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-NA1fZXBXh8Z"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentence):\n",
        "    \"\"\"\n",
        "    This function takes a sentence as input and performs various text preprocessing steps on it,\n",
        "    including removing punctuation, stop words, and stemming each word in the sentence.\n",
        "    \"\"\"\n",
        "    # tokenizing the sentence\n",
        "    tokens = tokenizer(sentence)\n",
        "    \n",
        "    # removing stop words\n",
        "    tokens = stopword_destroyer(tokens)\n",
        "\n",
        "    # stemming each word in the sentence\n",
        "    tokens = stemmerizer(tokens)\n",
        "\n",
        "    # return the preprocessed sentence as a list of words\n",
        "    return tokens"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JtV_a4pxYO11"
      },
      "source": [
        "What exactly does our preprocessing do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RV7mqHxX01X",
        "outputId": "382329f0-026b-4235-ee88-87f0d1054be3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id', 'respond', 'go']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = preprocess(example)\n",
        "tokens"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pz-Nr-JxYXW1"
      },
      "source": [
        "First, the `preprocess` function removes all punctuation marks from the sentence using the `string.punctuation` module. Then, the sentence is tokenized into a list of words using the nltk.word_tokenize method.\n",
        "\n",
        "Next, the function removes stop words, which are common words that do not carry much meaning in the sentence, such as \"a\", \"an\", \"the\", \"of\", and so on. In this case, the function is using a pre-defined list of stop words to remove them from the list of tokens.\n",
        "\n",
        "After that, the function performs stemming on each word in the sentence, which involves converting the words into their root or base form, called their stem. The function uses a stemmer to perform this task.\n",
        "\n",
        "Finally, the preprocessed words are returned as a list."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-aeCAOYa0Y"
      },
      "source": [
        "#### A bag-of-words representation of a sentence\n",
        "\n",
        "The main goal of the `bag_of_words` function is to convert a sentence into a numerical representation that captures the presence or absence of each known word in the vocabulary of known words (we will build our vocabulary soon!).\n",
        "\n",
        "Here is how the function works:\n",
        "\n",
        "The bag_of_words function takes a tokenized sentence and a list of all known words in the vocabulary as input, and creates a bag of words representation for the given sentence. It initializes the bag with zeros for each word in the vocabulary, and updates the bag with 1 for each word in the sentence that exists in the vocabulary. The function returns a numpy array representing the bag of words with 1 for each known word that exists in the sentence, 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uMPIki8ZYSHt"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(tokenized_sentence, map):\n",
        "    \"\"\"\n",
        "    Create a bag of words representation for a given tokenized sentence.\n",
        "    \"\"\"\n",
        "    # initialize the bag with zeros for each word in the vocabulary\n",
        "    bag = np.zeros(len(map), dtype=np.int8)\n",
        "\n",
        "    # update the bag with 1 for each word in the sentence that exists in the vocabulary\n",
        "        \n",
        "    for token in tokenized_sentence:\n",
        "      try:\n",
        "        bag[map[token]] = 1\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    return bag"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NAwRtxnFYkDu"
      },
      "source": [
        "## Loading and Preprocessing the Data\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UTEQvloeYrsW"
      },
      "source": [
        "We will now load our data from the intents file and preprocess its content using the logic we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zsqD23DIYeAg"
      },
      "outputs": [],
      "source": [
        "def fullDataPrep(df, map=None, all_words_list=None):\n",
        "  # build a set of all words if map is none\n",
        "  if map is None:\n",
        "    all_words = {}\n",
        "\n",
        "  preprocessed_list = []\n",
        "  for sentence in df['text']:\n",
        "    preprocessed = preprocess(sentence)\n",
        "    preprocessed_list.append(preprocessed)\n",
        "\n",
        "    if map is None:\n",
        "      for token in preprocessed:\n",
        "        if token in all_words:\n",
        "          all_words[token] += 1\n",
        "        else:\n",
        "          all_words[token] = 0\n",
        "\n",
        "  if map is None:\n",
        "    keys_to_delete = []\n",
        "    for key, value in all_words.items():\n",
        "        if value <= 5:\n",
        "            keys_to_delete.append(key)\n",
        "\n",
        "    for key in keys_to_delete:\n",
        "        del all_words[key]\n",
        "\n",
        "  # order set by making it a sorted list if map is none\n",
        "  if map is None:\n",
        "    all_words_list = sorted(list(all_words.keys()))\n",
        "  \n",
        "  # create a mapping from words to corresponding index if map is \n",
        "  # none\n",
        "  # this is an optimization... \n",
        "  if map is None:\n",
        "    map = {}\n",
        "    for i in range(len(all_words_list)):\n",
        "      word = all_words_list[i]\n",
        "      map[word] = i\n",
        "\n",
        "  # build new dataframe with bow repr\n",
        "  bow_array = []\n",
        "  for sentence in preprocessed_list:\n",
        "    row = bag_of_words(sentence, map)\n",
        "    bow_array.append(row)\n",
        "\n",
        "  bow_array = np.array(bow_array)\n",
        "    \n",
        "  bow_dict = {}\n",
        "  for i in range(len(all_words_list)):\n",
        "    word = all_words_list[i]\n",
        "    bow_dict[word] = bow_array[:, i]\n",
        "\n",
        "  return pd.DataFrame(bow_dict), map, all_words_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aIOwpLeBZOr7",
        "outputId": "51636bb7-da77-44e8-a3b8-79ae431be8cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>09</th>\n",
              "      <th>1</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>10th</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>...</th>\n",
              "      <th>yucki</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yup</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>ï¿½</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27475</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27476</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27477</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27478</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27479</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27480 rows × 2969 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  09  1  10  100  1000  10th  11  12  13  ...  yucki  yum  yummi  yup  \\\n",
              "0      0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "1      0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "2      0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "3      0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "4      0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "...   ..  .. ..  ..  ...   ...   ...  ..  ..  ..  ...    ...  ...    ...  ...   \n",
              "27475  0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "27476  0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "27477  0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "27478  0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "27479  0   0  0   0    0     0     0   0   0   0  ...      0    0      0    0   \n",
              "\n",
              "       zealand  zero  zombi  zone  zoo  ï¿½  \n",
              "0            0     0      0     0    0    0  \n",
              "1            0     0      0     0    0    0  \n",
              "2            0     0      0     0    0    0  \n",
              "3            0     0      0     0    0    0  \n",
              "4            0     0      0     0    0    0  \n",
              "...        ...   ...    ...   ...  ...  ...  \n",
              "27475        0     0      0     0    0    0  \n",
              "27476        0     0      0     0    0    0  \n",
              "27477        0     0      0     0    0    0  \n",
              "27478        0     0      0     0    0    0  \n",
              "27479        0     0      0     0    0    0  \n",
              "\n",
              "[27480 rows x 2969 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_train, map, all_words = fullDataPrep(train)\n",
        "new_train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu14bHrGZrr4"
      },
      "source": [
        "## Create and Training a Model\n",
        "\n",
        "First, we are going to define our input features(X_train) and our target vector(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZu4xX_iZUmh",
        "outputId": "e6e34117-1b38-4914-9505-ec1823bc6952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     neutral\n",
              "1    negative\n",
              "2    negative\n",
              "3    negative\n",
              "4    negative\n",
              "Name: sentiment, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train = new_train, train['sentiment']\n",
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "78NiquT7Zn3V"
      },
      "outputs": [],
      "source": [
        "def y_encode(row):\n",
        "  \"\"\"\n",
        "  encode the target column into integers we can work with\n",
        "  \"\"\"\n",
        "  if row == 'negative':\n",
        "    return 0\n",
        "  elif row =='neutral':\n",
        "    return 1\n",
        "  return 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4X8elPn1Z90R"
      },
      "outputs": [],
      "source": [
        "y_train = pd.Series(y_train.apply(y_encode))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYgQyO4lF8TE",
        "outputId": "c5a4d7af-68f0-44c0-c7b7-2ae93ab6db9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "27476    0\n",
              "27477    0\n",
              "27478    2\n",
              "27479    2\n",
              "27480    1\n",
              "Name: sentiment, Length: 27480, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0AaNl4f_jMzc"
      },
      "source": [
        "### Your Turn: Fit and Predict a model\n",
        "\n",
        "Though you do not have to use Logistic Regression, it is a simple method to start out with and use as a baseline. That being said, there are many other models out there-- check them out!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "Ak_WUw2YaERP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "reg = lr.fit(X_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlr7PgMZaLFf"
      },
      "source": [
        "### Test Data\n",
        "\n",
        "Now, try the same process on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0abNT4McaRPw"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"/Users/austinfroste/Documents/CSNL/narrative_sentiment_analysis/Transcripts/nsa_data/transcript_aggregate.csv\")\n",
        "test = test.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sub_num</th>\n",
              "      <th>run_type</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d01_01</td>\n",
              "      <td>idea</td>\n",
              "      <td>My religious beliefs have always been like a r...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d01_01</td>\n",
              "      <td>idea</td>\n",
              "      <td>Um when we're younger, we don't really have mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d01_01</td>\n",
              "      <td>idea</td>\n",
              "      <td>You just don't get that choice</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d01_01</td>\n",
              "      <td>idea</td>\n",
              "      <td>Um but when you were old enough, we finally ge...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d01_01</td>\n",
              "      <td>idea</td>\n",
              "      <td>And I approach life very cautiously</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12007</th>\n",
              "      <td>d45_02</td>\n",
              "      <td>pos_past</td>\n",
              "      <td>And I never looked so thin and in such good sh...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12008</th>\n",
              "      <td>d45_02</td>\n",
              "      <td>pos_past</td>\n",
              "      <td>Like, we'd be out there for about six hours an...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12009</th>\n",
              "      <td>d45_02</td>\n",
              "      <td>pos_past</td>\n",
              "      <td>And so we be pulling out and be like, \"Oh, tha...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12010</th>\n",
              "      <td>d45_02</td>\n",
              "      <td>pos_past</td>\n",
              "      <td>That's your elbow</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12011</th>\n",
              "      <td>d45_02</td>\n",
              "      <td>pos_past</td>\n",
              "      <td>So it was a really incredible experience</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      sub_num  run_type                                               text  \\\n",
              "0      d01_01      idea  My religious beliefs have always been like a r...   \n",
              "1      d01_01      idea  Um when we're younger, we don't really have mu...   \n",
              "2      d01_01      idea                     You just don't get that choice   \n",
              "3      d01_01      idea  Um but when you were old enough, we finally ge...   \n",
              "4      d01_01      idea                And I approach life very cautiously   \n",
              "...       ...       ...                                                ...   \n",
              "12007  d45_02  pos_past  And I never looked so thin and in such good sh...   \n",
              "12008  d45_02  pos_past  Like, we'd be out there for about six hours an...   \n",
              "12009  d45_02  pos_past  And so we be pulling out and be like, \"Oh, tha...   \n",
              "12010  d45_02  pos_past                                  That's your elbow   \n",
              "12011  d45_02  pos_past           So it was a really incredible experience   \n",
              "\n",
              "      sentiment  \n",
              "0       neutral  \n",
              "1       neutral  \n",
              "2       neutral  \n",
              "3       neutral  \n",
              "4       neutral  \n",
              "...         ...  \n",
              "12007  positive  \n",
              "12008  positive  \n",
              "12009  positive  \n",
              "12010  positive  \n",
              "12011  positive  \n",
              "\n",
              "[12000 rows x 4 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "JM3ev6eKgAFH"
      },
      "outputs": [],
      "source": [
        "new_test, map, all_words = fullDataPrep(test, map, all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gTz4D9EtgFfA"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = new_test, test['sentiment']\n",
        "y_test = pd.Series(y_test.apply(y_encode))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_381vQKdF4Xs",
        "outputId": "a38d20a3-2e5b-45ac-8ba1-341291e893d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        1\n",
              "4        1\n",
              "        ..\n",
              "12007    2\n",
              "12008    2\n",
              "12009    2\n",
              "12010    2\n",
              "12011    2\n",
              "Name: sentiment, Length: 12000, dtype: int64"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rg73Mmn5jn8L"
      },
      "source": [
        "### Get the accuracy of your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "XhL3tYcBa3Ht",
        "outputId": "18974cd6-5f7a-45b8-95cb-27b80dfe8fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.35175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Predict the labels for the test data\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PR9yvdjEG07"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
